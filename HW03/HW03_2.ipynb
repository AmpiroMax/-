{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"HW03.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"rGRQOy4kxGMa"},"source":["# ДЗ №3 \n","## Обучение моделей глубокого обучения на PyTorch"]},{"cell_type":"code","metadata":{"id":"h-UHDMjbxGMd","executionInfo":{"status":"ok","timestamp":1618254799160,"user_tz":-180,"elapsed":3813,"user":{"displayName":"Maxim Patrat","photoUrl":"","userId":"03432484373265500035"}}},"source":["import torch\n","import torchvision\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from typing import Tuple, List, Type, Dict, Any"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"L5ZSdbtKxGMf","executionInfo":{"status":"ok","timestamp":1618254799161,"user_tz":-180,"elapsed":3807,"user":{"displayName":"Maxim Patrat","photoUrl":"","userId":"03432484373265500035"}}},"source":["torch.manual_seed(0)\n","np.random.seed(0)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"iSWhgc6FxGMh","executionInfo":{"status":"ok","timestamp":1618254799161,"user_tz":-180,"elapsed":3800,"user":{"displayName":"Maxim Patrat","photoUrl":"","userId":"03432484373265500035"}}},"source":["class Perceptron(torch.nn.Module):\n","    \n","    def __init__(self, \n","                 input_resolution: Tuple[int, int] = (28, 28),\n","                 input_channels: int = 1, \n","                 hidden_layer_features: List[int] = [256, 256, 256],\n","                 activation: Type[torch.nn.Module] = torch.nn.ReLU,\n","                 num_classes: int = 10):\n","\n","        super().__init__()\n","        \n","        self.layer_1 = torch.nn.Linear(in_features=784, out_features=256, bias=True)\n","        self.activation_1 = activation()\n","        self.layer_2 = torch.nn.Linear(in_features=256, out_features=128, bias=True)\n","        self.activation_2 = activation()\n","        self.layer_3 = torch.nn.Linear(in_features=128, out_features=64, bias=True)\n","        self.activation_3 = activation()\n","        self.layer_4 = torch.nn.Linear(in_features=64, out_features=num_classes, bias=True)\n","        \n","    \n","    def forward(self, x):\n","        x = self.layer_1(x)\n","        x = self.activation_1(x)\n","        x = self.layer_2(x)\n","        x = self.activation_2(x)\n","        x = self.layer_3(x)\n","        x = self.activation_3(x)\n","        x = self.layer_4(x)\n","        return x"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uv7gx6kxxGMi","executionInfo":{"status":"ok","timestamp":1618254799162,"user_tz":-180,"elapsed":3794,"user":{"displayName":"Maxim Patrat","photoUrl":"","userId":"03432484373265500035"}},"outputId":"39bdb5cf-5ff3-4f55-9c5f-fffd4e67dc53"},"source":["model = Perceptron()\n","print(model)\n","print('Total number of trainable parameters', \n","      sum(p.numel() for p in model.parameters() if p.requires_grad))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Perceptron(\n","  (layer_1): Linear(in_features=784, out_features=256, bias=True)\n","  (activation_1): ReLU()\n","  (layer_2): Linear(in_features=256, out_features=128, bias=True)\n","  (activation_2): ReLU()\n","  (layer_3): Linear(in_features=128, out_features=64, bias=True)\n","  (activation_3): ReLU()\n","  (layer_4): Linear(in_features=64, out_features=10, bias=True)\n",")\n","Total number of trainable parameters 242762\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tpiG6E0vxGMm","executionInfo":{"status":"ok","timestamp":1618254799162,"user_tz":-180,"elapsed":3789,"user":{"displayName":"Maxim Patrat","photoUrl":"","userId":"03432484373265500035"}}},"source":["train_transforms = torchvision.transforms.Compose([                                                 \n","    torchvision.transforms.RandomRotation(24),   \n","    torchvision.transforms.ToTensor(),\n","    torchvision.transforms.Normalize((0, ), (0.3, ))\n","])\n","\n","val_transforms = torchvision.transforms.Compose([\n","    torchvision.transforms.ToTensor(),\n","    torchvision.transforms.Normalize((0, ), (0.3, ))\n","])"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"frwLYqE_xGMm"},"source":["train_dataset = torchvision.datasets.MNIST(root='./mnist', \n","                                           train=True, \n","                                           download=True,\n","                                           transform=train_transforms)\n","\n","val_dataset = torchvision.datasets.MNIST(root='./mnist', \n","                                         train=False, \n","                                         download=True,\n","                                         transform=val_transforms)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sIRUJnc3xGMn"},"source":["indices = np.random.randint(0, len(train_dataset), size=16)\n","\n","fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(32, 32))\n","for i, row in enumerate(axes):\n","    for j, ax in enumerate(row):\n","        sample_index = indices[i*4+j]\n","        sample, label = train_dataset[sample_index]\n","        ax.imshow(sample[0])\n","        ax.set_title(label)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_5VVGvdrxGMo","executionInfo":{"status":"ok","timestamp":1618254815333,"user_tz":-180,"elapsed":19770,"user":{"displayName":"Maxim Patrat","photoUrl":"","userId":"03432484373265500035"}}},"source":["def train_model(model: torch.nn.Module, \n","                train_dataset: torch.utils.data.Dataset,\n","                val_dataset: torch.utils.data.Dataset,\n","                loss_function: torch.nn.Module = torch.nn.CrossEntropyLoss(),\n","                optimizer_class: Type[torch.optim.Optimizer] = torch.optim,\n","                optimizer_params: Dict = {},\n","                initial_lr = 0.01,\n","                lr_scheduler_class: Any = torch.optim.lr_scheduler.ReduceLROnPlateau,\n","                lr_scheduler_params: Dict = {},\n","                batch_size = 64,\n","                max_epochs = 1000,\n","                early_stopping_patience = 20):\n","    optimizer = torch.optim.Adam(model.parameters(), lr=initial_lr, **optimizer_params)\n","    lr_scheduler = lr_scheduler_class(optimizer, **lr_scheduler_params)\n","    \n","    train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n","    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n","\n","    best_val_loss = None\n","    best_epoch = None\n","\n","    for epoch in range(max_epochs):\n","        \n","        print(f'Epoch {epoch}')\n","        \n","        train_single_epoch(model, optimizer, loss_function, train_loader)\n","        val_metrics = validate_single_epoch(model, loss_function, val_loader)\n","\n","        print(f'Validation metrics: \\n{val_metrics}')\n","        \n","        lr_scheduler.step(val_metrics['loss'])\n","        \n","        if best_val_loss is None or best_val_loss > val_metrics['loss']:\n","            print(f'Best model yet, saving')\n","            best_val_loss = val_metrics['loss']\n","            best_epoch = epoch\n","            torch.save(model, './best_model.pth')\n","            \n","        if epoch - best_epoch > early_stopping_patience:\n","            print('Early stopping triggered')\n","            return\n","            "],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"K-3ARuByxGMp","executionInfo":{"status":"ok","timestamp":1618254815333,"user_tz":-180,"elapsed":19631,"user":{"displayName":"Maxim Patrat","photoUrl":"","userId":"03432484373265500035"}}},"source":["def train_single_epoch(model: torch.nn.Module,\n","                       optimizer: torch.optim.Optimizer, \n","                       loss_function: torch.nn.Module, \n","                       data_loader: torch.utils.data.DataLoader):\n","    loss = None\n","    \"\"\"\n","    У меня была идея связанная с тем, как сворачивать матрицу картинки в массив.\n","    https://www.youtube.com/watch?v=3s7h2MHQtxc\n","    Например, как показано в этом видеоролике, с помощью space filling curves, \n","    мы смогли бы сохранить пространственное свойство картинок. \n","\n","    Однако, т.к. мы работаем с картинками одного и того же разрешения, нам это \n","    никак не поможет. Но всё-таки идея, как мне кажется неплохая, поэтому я хотел бы узнать,\n","    что вы думаете по этому поводу. Как сильно я ошибаюсь и в чем не прав.\n","    \"\"\"\n","    for x_batch, y_batch in data_loader:\n","        x_batch = x_batch.view(x_batch.shape[0], -1)\n","\n","        y_pred = model(x_batch)\n","        loss = loss_function(y_pred, y_batch)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    print(loss.item())\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vx_57dxixGMq","executionInfo":{"status":"ok","timestamp":1618254815334,"user_tz":-180,"elapsed":19507,"user":{"displayName":"Maxim Patrat","photoUrl":"","userId":"03432484373265500035"}}},"source":["def validate_single_epoch(model: torch.nn.Module,\n","                          loss_function: torch.nn.Module, \n","                          data_loader: torch.utils.data.DataLoader):\n","    loss_history = []\n","    acc = 0\n","\n","    \n","    for x_batch, y_batch in data_loader:\n","        x_batch = x_batch.view(x_batch.shape[0], -1)\n","\n","        y_pred = model(x_batch)\n","\n","        loss = loss_function(y_pred, y_batch)\n","        loss_history.append(loss.item())\n","\n","        for i, pred in enumerate(y_pred):\n","            if torch.argmax(pred) == y_batch[i]:\n","                acc += 1 \n","    acc /= ((len(data_loader) - 1) * 64 + 32)\n","\n","    return {\"loss\": np.mean(loss_history), \"accuracy\": acc}\n","    "],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"KMg4_vM5xGMr"},"source":["train_model(model, \n","            train_dataset=train_dataset, \n","            val_dataset=val_dataset, \n","            loss_function=torch.nn.CrossEntropyLoss(), \n","            initial_lr=0.01,\n","            lr_scheduler_class = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts,\n","            lr_scheduler_params = {\"T_0\" : 100})\n","\"\"\"\n","Данные последней лучшей модели:\n","    Epoch 26\n","    Validation metrics: \n","    {'loss': 0.11119568567803859, 'accuracy': 0.9728434504792333}\n","    Best model yet, saving\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W0sem6z5xGMr"},"source":["train_model(model, \n","            train_dataset=train_dataset, \n","            val_dataset=val_dataset, \n","            loss_function=torch.nn.CrossEntropyLoss(), \n","            initial_lr=0.01,\n","            lr_scheduler_class = torch.optim.lr_scheduler.StepLR,\n","            lr_scheduler_params = {\"step_size\" : 50})\n","\"\"\"\n","Данные последней лучшей модели:\n","    Epoch 31\n","    Validation metrics: \n","    {'loss': 0.13994677272880343, 'accuracy': 0.9656549520766773}\n","    Best model yet, saving\n","\"\"\"\n","\n","\"\"\"\n","Я поменял только способ изменения lr. Loss возрос на 0.02 и не был стабилен.\n","На протяжении обучения, модель показывала loss вплоть до 0.31(...). Когда модель\n","с теплым рестартом на lr имела стабильный loss и accuracy у неё по итогу выше.\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"COkmEA2Fq77V","executionInfo":{"status":"ok","timestamp":1618260039305,"user_tz":-180,"elapsed":1070,"user":{"displayName":"Maxim Patrat","photoUrl":"","userId":"03432484373265500035"}},"outputId":"523dd462-63e0-4ae0-b9c5-0d9c0a291e2a"},"source":["model1 = Perceptron(activation = torch.nn.LeakyReLU)\n","print(model1)\n","print('Total number of trainable parameters', \n","      sum(p.numel() for p in model.parameters() if p.requires_grad))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Perceptron(\n","  (layer_1): Linear(in_features=784, out_features=256, bias=True)\n","  (activation_1): LeakyReLU(negative_slope=0.01)\n","  (layer_2): Linear(in_features=256, out_features=128, bias=True)\n","  (activation_2): LeakyReLU(negative_slope=0.01)\n","  (layer_3): Linear(in_features=128, out_features=64, bias=True)\n","  (activation_3): LeakyReLU(negative_slope=0.01)\n","  (layer_4): Linear(in_features=64, out_features=10, bias=True)\n",")\n","Total number of trainable parameters 242762\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xk7lA39ey0mW","executionInfo":{"status":"ok","timestamp":1618260039305,"user_tz":-180,"elapsed":870,"user":{"displayName":"Maxim Patrat","photoUrl":"","userId":"03432484373265500035"}},"outputId":"4b1529ca-9f9d-4d76-ef6e-613c10a34841"},"source":["model2 = Perceptron(activation = torch.nn.Softplus)\n","print(model2)\n","print('Total number of trainable parameters', \n","      sum(p.numel() for p in model.parameters() if p.requires_grad))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Perceptron(\n","  (layer_1): Linear(in_features=784, out_features=256, bias=True)\n","  (activation_1): Softplus(beta=1, threshold=20)\n","  (layer_2): Linear(in_features=256, out_features=128, bias=True)\n","  (activation_2): Softplus(beta=1, threshold=20)\n","  (layer_3): Linear(in_features=128, out_features=64, bias=True)\n","  (activation_3): Softplus(beta=1, threshold=20)\n","  (layer_4): Linear(in_features=64, out_features=10, bias=True)\n",")\n","Total number of trainable parameters 242762\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TP_0-g-10E7l"},"source":["\"\"\"\n","Теперь я возьму метод обычения с lr_schedule = CosineAnnealingWarmRestarts\n","и попробую узнать, какая функция активация лучше. Для тестов я взял LeakyReLU\n","и Softplus как родственников ReLU. Возможно стоит ещё проверить что-нибудь из \n","класса сигмоид\n","\"\"\"\n","train_model(model1, \n","            train_dataset=train_dataset, \n","            val_dataset=val_dataset, \n","            loss_function=torch.nn.CrossEntropyLoss(), \n","            initial_lr=0.01,\n","            lr_scheduler_class = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts,\n","            lr_scheduler_params = {\"T_0\" : 100})\n","\"\"\"\n","Epoch 7\n","Validation metrics: \n","{'loss': 0.10283183453893392, 'accuracy': 0.9702476038338658}\n","Best model yet, saving\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2LPGvfgB03qc"},"source":["train_model(model2, \n","            train_dataset=train_dataset, \n","            val_dataset=val_dataset, \n","            loss_function=torch.nn.CrossEntropyLoss(), \n","            initial_lr=0.01,\n","            lr_scheduler_class = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts,\n","            lr_scheduler_params = {\"T_0\" : 100})\n","\"\"\"\n","Epoch 12\n","Validation metrics: \n","{'loss': 0.12079034244662423, 'accuracy': 0.9681509584664537}\n","Best model yet, saving\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ie6GODn10_LF"},"source":[""],"execution_count":null,"outputs":[]}]}